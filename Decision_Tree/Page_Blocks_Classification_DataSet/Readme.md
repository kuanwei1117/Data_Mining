#决策树算法分析Page Blocks Classification Data Set 数据集

##算法原理：
一棵决策树包含一个根结点 、若干个内部结点和若干个叶结点 ；叶结点对应于决策结果，其他每个结点则对应于一个属性 ；每个结点包含的样本集合根据属性测试的结果被划分到子结点中 ;根结点包含样本全集．从根结点到每个叶结点的路径对应了一个判定测试序列 ．决策树学习的目的是为了产生一棵泛化能力强，即处理未见示例能力强的决策树，其基本流程遵循简单且直观的分治策略。

##思路分析：
将原始资料文挡共5473笔,每笔依据空格分开读入资料 dataSet 中, 并且创建 标签向量featLabels 的 list, 传入 createTree function 的参数后, 每个节点依据各个特征计算entropy选取最佳特征(最大信息增益)分类建树

##测试结果：
从上图可看到经过反覆的训练之后，准确率可达99.5%
