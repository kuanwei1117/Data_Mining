用Adaboost算法分析student-mat以及student-por

算法原理：
前一个基本分类器被错误分类的样本的权值会增大，而正确分类的样本的权值会减小，并再次用来训练下一个基本分类器。同时，在每一轮迭代中，加入一个新的弱分类器，直到达到某个预定的足够小的错误率或达到预先指定的最大迭代次数才确定最终的强分类器

思路分析：
原始资料分为student-mat.csv与student-por.csv两份档案，首先先透过label将两份档案合并，接着创建字典将自变数处理为数值，接着透过buildStump找到误差最小的分类方式，并透过adaBoostTrainDS组合40个弱分类器，定义adaBoost，最后遍历所有分类器，进行分类，并打印出正确率。

测试结果：
经过反覆的训练之后，準確率可達到93.91%
